[
{
	"uri": "/1_moduleone.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction Workshop Overview This workshop focuses on two primary use cases the CloudSphere Platform is suited for; Migration Planning and Modernization/Optimization.\nThe Migration Planning portion will include a hands-on deployment of a CloudSphere virtual appliance and migration data exploration.\nThe Modernization \u0026amp; Optimization portion will focus on data insights related to optimization of environments, as well as modernization of applications and services.\nWorkshop Overview Prerequisites (5 minutes) Module 1: Appliance Deployment and Scan (20 minutes) Module 2: Migration Data Exploration (15 minutes) Module 3: Modernization \u0026amp; Optimization (15 minutes) The examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.\nWorkshop Background Next, we\u0026rsquo;ll cover the workshop background\n"
},
{
	"uri": "/",
	"title": "Migration Planning and Optimization &amp; Modernization with CloudSphere",
	"tags": [],
	"description": "",
	"content": "Migration Planning and Optimization \u0026amp; Modernization with CloudSphere Welcome This workshop is intended to provide hands-on training of the CloudSphere platform for Migration Planning and Optimization \u0026amp; Modernization. This workshop will be broken out in to two modules, one for Migration Planning and a second for Optimization and Moderization.\nCloudSphere’s IT Asset Management Platform enables enterprise companies to discover, plan, migrate, and manage IT assets for multicloud and on-premises environments. Our multi-cloud solutions use a unique application centric approach to allow users to see beyond individual cloud resources and manage applications in the cloud.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.\n"
},
{
	"uri": "/3_modulethree/31_partnersetup.html",
	"title": "Partner Setup Instructions",
	"tags": [],
	"description": "",
	"content": "Partner Setup Instructions Submodule One Heading This paragraph block should be an introduction to the submodule.\nSubmodule One Subheading This paragraph block should be utilized to start the submodule. Next Section OR Conclusion Heading This paragraph block can be utilized to lead into the next section of the workshop (which might be a conclusion) or be a conclusion itself.\nExample Guidance Content Below Do you require attendees to sign up for things? Introduction In this section, we are going to discuss tasks and concepts like retrieving access tokens and other configurations within some integration services.\nDocker Hub Docker Hub is a service provided by Docker for finding and sharing container images with your team. It is the world’s largest repository of container images with an array of content sources including container community developers, open source projects and independent software vendors (ISV) building and distributing their code in containers.\nCreate a Docker Hub Access Token The pipeline will package the application into a Docker image. It then pushes that image a public Docker Hub image repository so that it will be available to the deployment segment of the pipeline. To push or upload the newly-built Docker image, the pipeline will need an access token to authorize transaction on your Docker Hub account. You will need to create a new access token (https://docs.docker.com/docker-hub/access-tokens/) and store it for use in later modules. To create your new access tokens:\nLog in to hub.docker.com\rClick your username in the top right corner and select Account Settings\rSelect Security \u0026gt; New Access Token.\rAdd a description for your token that indicates where the token will be used, or that sets a purpose for the token\rCopy the token that appears on the screen and record it in a safe location for use in future modules. Make sure you do this now! Once you close this prompt, Docker will never show the token again and you will have to create a new one\rWarning: Docker Hub credentials and access tokens must be protected and not shared with unauthorized parties to prevent exposure and unauthorized access.\nNow that you have created and safely recorded your new access token, let’s move to the next section and create a new Snyk Access token.\nSnyk Snyk is an open source security platform designed to help software-driven businesses enhance developer security. Snyk’s dependency scanner makes it the only solution that seamlessly and proactively finds, prioritizes, and fixes vulnerabilities and license violations in open source dependencies and container images.\nCreate Snyk Access Token Visit your Snyk account (Account Settings \u0026gt; API Token section) (https://app.snyk.io/account)\rIn the KEY field, select click to show, then select and copy your API token from the field\rPaste the token that appears on the screen in a safe location for use in future modules\rWarning: Your Snyk access token must be protected and not shared with unauthorized parties to prevent exposure and unauthorized access.\nYou can read more about Snyk Access Token from their docs here.\nGreat, you have created and safely stored your newly created Snyk access token, Now, let’s create the Terraform Cloud access token.\nTerraform Cloud Terraform Cloud is an application that helps teams use Terraform together. It manages Terraform runs in a consistent and reliable environment, and includes easy access to shared state and secret data, access controls for approving changes to infrastructure, a private registry for sharing Terraform modules, detailed policy controls for governing the contents of Terraform configurations, and more.\nYou will be using Terraform Cloud to store the Terraform state of the infrastructures your pipeline will provision and deploy using Terraform in future modules.\nCreate Terraform Cloud Access Token Create a `[Terraform Cloud ](https://app.terraform.io/signup/account)` account\rCreate a new '[Terraform Cloud organization ] (https://learn.hashicorp.com/terraform/cloud-getting-started/signup#create-your-organization)'\rCreate a new '[Terraform Cloud workspace ] (https://learn.hashicorp.com/terraform/cloud-getting-started/create-workspace)' named: arm-aws-ecs\rClick the CLI-driven workflow option\rIn the workspace, click arm-aws-ecs \u0026gt; Settings \u0026gt; General then enable '[local execution mode] (https://www.terraform.io/docs/cloud/workspaces/settings.html#execution-mode)'\rGo to the '[User Settings section] (https://www.terraform.io/docs/cloud/users-teams-organizations/users.html#user-settings)' in the Terraform Cloud Dashboard\rIn the User Settings section, Create a new '[Terraform API token] (https://www.terraform.io/docs/cloud/users-teams-organizations/users.html#api-tokens)' then copy and paste the token in a secure location for later use.\rWarning: Your Terraform Cloud API token must be protected and not shared with unauthorized parties to prevent exposure and unauthorized access.\nGreat, you have created and safely stored your newly created Terraform Cloud API Token.\n"
},
{
	"uri": "/2_moduletwo_setup/21_applianceregistration.html",
	"title": "Registering the Virtual Appliance",
	"tags": [],
	"description": "",
	"content": "Registering the Virtual Appliance In order to scan an client environment, a virtual appliance must be deployed in the target network or segment. We have already deployed the appliance in our AWS sandbox using our Amazon Machine Image (AMI file) available in the AMI directory.\nCapture Appliance ID Since the virutal appliance is deployed, we now need to register the virtual appliance. Navigate to the IP address provided in your access email (?) in your browser to log in to the virtual appliance, the default credentials are Username: admin Password: admin\nUpon logging in to the appliance, the registration screen will be displayed. Copy the unique Appliance ID to your clipboard.\nGenerate License Key Navigate to the CloudSphere Platform at the address provided in your access email and enter the provided Organization to designate the proper tenant.\nOn the next screen, you can complete the login process using the credentials provided in your access email.\nNavigate to the Settings menu in the (bottom left) corner of the UI and click on the Appliances sub-menu.\nClick the Generate License button on the (top left center) of the UI to open the license creation window.\nPaste the Appliance ID in the first field and name the appliance appropriately (suggested conventions?) then click the Create Appliance button to generate the License. Copy this license to your clipboard with the icon in the lower right hand corner of the field.\nRegistering the Appliance With the License copied from the last step, navigate back to the browser tab with the Virtual Appliance and paste the License in to the License Key field and click next.\nSelect Finish on the next screen and the services running on the Virtual Appliance will restart to complete the registration process.\nNavigate back to the CloudSphere Platform in the Appliances section to confirm the Appliance registration was successful.\nCongratulations! You have successfully installed and registered your CloudSphere Virtual Appliance.\nAdditional details related to AWS appliance deployment and configuration available here:\n• Instructions for AWS Appliance installation - Appliance Installation - AWS https://docs.cloudsphere.com/hc/en-us/articles/5090846548123-Appliance-Installation-AWS\n• For Configuration use the following - Configuring the Virtual Appliance https://docs.cloudsphere.com/hc/en-us/articles/5090275699995-Configure-the-Virtual-Appliance\nAdditional details related to deployment in non-AWS environments available at the following links\n• VMware: https://docs.cloudsphere.com/hc/en-us/articles/5090855184539-Appliance-Installation-VMware\n• Hyper-V: https://docs.cloudsphere.com/hc/en-us/articles/5090860657819-Appliance-Installation-Hyper-V\n• Azure: https://docs.cloudsphere.com/hc/en-us/articles/5090858177307-Appliance-Installation-Azure-Marketplace-\n• GCP: https://docs.cloudsphere.com/hc/en-us/articles/5090847564315-Appliance-Installation-GCP\nConfiguring the Keychain Now that your Virtual Appliance is registered, we can proceed to Configuring the Keychain\n"
},
{
	"uri": "/1_moduleone/11_foreword.html",
	"title": "Workshop Background",
	"tags": [],
	"description": "",
	"content": "Workshop Background The Market Challenge IT estates are increasingly complex and are typically spread across physical and virtual infrastructure. CloudSphere gives AWS and it\u0026rsquo;s partners complete IT estate inventories, along with mapping of communications and dependencies. With these inventories and maps, clients can move to the cloud with confidence, while minimizing risk.\nChallenge Specifics Next, we\u0026rsquo;ll get in to the specifics of the challenges\n"
},
{
	"uri": "/1_moduleone/12_technicalissue_problem.html",
	"title": "Challenge Specifics",
	"tags": [],
	"description": "",
	"content": "Challenge Specifics Submodule Two Heading This paragraph block should be an introduction to the technical issue the solution is facing. An example of this can be seen at the bottom of this page. Next Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\nExample of content guidance Deploy Without Worry Deployments with Kubernetes? Kubernetes (k8s) is a container orchestration platform allowing organizations to scale their services and workloads quickly. If you are working with containers or microservices, k8s may be a great use case for you. Kubenetes deployments are container image deployments which target k8s-based environments.\nAmazon has released a managed k8s service called Elastic Kubernetes Service (EKS). Amazon EKS helps you provide highly-available and secure clusters and automates key tasks such as patching, node provisioning, and updates. While AWS provides the platform on which to run your containerize applications deploying them in a scalable, repeatable and reliable way is where Harness comes in.\nHow does Harness help with EKS deployments? Harness has first-class support for Kubernetes Resources. Harness can create scaffolding around Kubernetes Resources removing complexities around crafting your own resource definitions that are purpose made for deployments. Harness can offer granular deployment lifecycle support around different Kubernetes Resources supporting canary and blue/green deployments inside Kubernetes.\nWhy is Canary deployment tricky with EKS deployments? Canary Deployments are a progressive delivery pattern for rolling out releases to a subset of users. Canary Deployments can be complex because of the multiple phases and the judgment call of when to promote or rollback a canary. The Harness Platform has smart verification taking away the manual toil in verification and enables seamless Canary Deployments.\n"
},
{
	"uri": "/2_moduletwo_setup/22_configkeychain.html",
	"title": "Configuring the Keychain",
	"tags": [],
	"description": "",
	"content": " Configuring the Keychain In order to get accurate and detailed information about servers and services, the Application Discovery requires server Credentials to access information. Keychains are lists of Credentials.\nCreate a new Keychain First, we\u0026rsquo;ll need to create a new Keychain. Navigate to the Discovery menu on the (left nav bar) and select the sub-menu item title Keychains.\nClick the blue plus sign button in the upper right hand corner to start the Keychain creation process.\nSelect Cloud as the Keychain Location, name the Keychain and add a brief description.\nNote: Keychains and associated credentials can be stored on the cloud or locally on the appliance as needed. Cloud Keychains are more easily modified and can be updated simply via the CloudSphere UI. Locally stored credentials must be modified on the Virutal Appliance as needed.\nAdd Credentials Click on your newly created Keychain and click the blue button titled Add Credential in the upper left corner of this screen.\nReview the access email for the credentials provided and enter each of the credentials individually to add them to your Keychain.\nYou will also have the option to test the credentials that you just entered, which is helpful to make sure there are sufficient privledges.\nOnce all of the credentials have been added to the Keychain, you have completed the configuration of your Keychain. Well done!\nCreating a Scan Scope Now that we have our Keychain configured, we can move on to creating the Scan Scope\n"
},
{
	"uri": "/2_moduletwo_setup.html",
	"title": "Environment Scanning",
	"tags": [],
	"description": "",
	"content": "Virtual Appliance Registration and Scanning Workshop Highlights In this Workshop, you complete a series of steps in order to prepare to scan an environment using the CloudSphere Platform. By the end of this section, you will have scanned a sample environment and experienced the data collection process first-hand.\nThe steps will complete include:\nRegistering the Virtual Appliance Configuring the Keychain Configuring the Scan Scope Configuring the Scan Job Starting a Scan Job Basic output review REMOVE: Every introduction page should include the following warning label.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.\nRegistering the Virtual Appliance The first step in the process will be registering the Virtual Appliance.\n"
},
{
	"uri": "/1_moduleone/13_whoweare.html",
	"title": "About CloudSphere",
	"tags": [],
	"description": "",
	"content": "About CloudSphere A little about us\u0026hellip; CloudSphere was founded through a merger of two companies, Hypergrid and iQuate. With legacy roots in cloud asset management and software asset management, an industry-leading cloud governance was created to meet the needs of businesses.\nCloudSphere is an AWS ISV Partner and part of the APN Partner program with competencies in Migration \u0026amp; Modernization and Cloud Operations Software. CloudSphere can be procured through the AWS Marketplace or via Private Offer.\nWorkshop Prerequisites Next, we\u0026rsquo;ll review some workshop prerequisites to make sure that you have the necessary access\n"
},
{
	"uri": "/2_moduletwo_setup/23_configscanscope.html",
	"title": "Creatinging a Scan Scope",
	"tags": [],
	"description": "",
	"content": " Creatinging a Scan Scope CloudSphere CAM discovers devices that exist in your IT universe by executing Scan Jobs. The Scan jobs scan endpoints within a specified network boundary (Subnets, IP Ranges, IPs), which is defined using Scan Scope(s).\nWhile configuring a Scan Job we first need to identify and define Scan Scope(s), and eventually add them to it.\nA Scan Scope provides a list of target IP addresses or hostnames that we want to be scanned while we execute a Scan Job. It also contains information about the Scope Type (target environment - Private Network, Amazon EC2, Azure, Google Cloud Platform).\nIt can be defined using the following:\nList - specified as a list of IP addresses or hostnames IP Range - specified by a start and end IP address IP Subnet - specified by a network address and subnet mask\nCreate a new Scan Scope From the Discovery menu, navigate to the Scopes sub-menu\nClick the blue plus sign in the upper right hand corner to start creating your new scope.\nAdd a name and description to the Scope and select \u0026ldquo;Amazon EC2\u0026rdquo; as the Scope Type.\nAdding Targets to Scope Click on your newly created scope to\nAdding Exclusions An exclusion is a scope (Target IPs) that you want to exclude or avoid scanning. By using this step, you can add a list of target IPs that you would like to avoid scanning. You can either choose an existing exclusion from the list which you have already created or create a new exclusion similar to creating a new scope. Exclusions are particularly useful when you are scanning a subnet of IPs, as one example.\nWe\u0026rsquo;ll skip this step for today\u0026rsquo;s exercise, so you have now completed the creation of a new Scan Scope, nicely done!\nAdditional reference documentation related to scanning: Scanning Best Practices: https://docs.cloudsphere.com/hc/en-us/articles/6259702566939-Scanning-Best-Practices Identifying Network Segments for Discovery:https://docs.cloudsphere.com/hc/en-us/articles/5046106276635-Step-1-Identify-Network-Segments-for-Discovery\nConfiguring the Scan Job Now that we have a Scan Scope created, we can proceed with configuring the Scan Job\n"
},
{
	"uri": "/3_modulethree.html",
	"title": "Partner Setup",
	"tags": [],
	"description": "",
	"content": "Partner Setup Module Three Heading This paragraph block should be an introduction to the module about requirements the partner may need for their audience members. Examples include signing up for the partner platform or installing an agent.\nModule Three Subheading This paragraph block should be utilized to briefly explain the submodules. Partner Setup Instructions A brief overview of submodule one.\nREMOVE: Every introduction page should include the following warning label.\nThe examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.\nNext Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\n"
},
{
	"uri": "/2_moduletwo_setup/24_configscanjob.html",
	"title": "Configuring the Scan Job",
	"tags": [],
	"description": "",
	"content": " Configuring the Scan Job Now that we have our Keychain and Scope configured, we can configure our Scan Job\nCreate New Scan Job Navigate to the Discovery menu in the left nav and click on the sub-menu titled Scan Jobs.\nIn the upper right hand corner, click the blue plus sign.\nAdd a name to the job and a description as desired and click the button titled Create New Scan Job\nSelect Scan Job Type Confirm the type is set to \u0026ldquo;Sequential\u0026rdquo;\nSet the Scan Details Select the Appliance that you previously registered in the first drop down box\nThe location field can be selected, but is optional\nThe Enablings field configures additional details related to the scanning job, including the ability to collect basic performance metrics on each endpoint. For now, we\u0026rsquo;ll leave this blank, but in live deployments where telemetry data is desired, we\u0026rsquo;d enable the ServerMetrics option. This option deploys a lightweight script on each endpoint that reads existing data sources, such as perfmon\nLeave the Maximum duration set to 2 (hours) for now. This can be used to (minimize the chances a unsuccessful scan job will run before timing out?)\nClick the Update button in the upper right hand corner to save the changes\nAdd the Scope Select the previously created scope to add it to this scan job. Note: you can only add one Scope per Scan Job; if you wish to have multiple Scopes, you will also need multiple Scan Jobs.\nClick the Update button in the upper right hand corner to save the changes\nAdd Exclusions (optional) We won\u0026rsquo;t add any exclusions today, but this is where exclusions to the Scan Job can be added to further refine the scope to omit any endpoints specified. An exclusion is set up as a Scope, as noted in the previous section.\nAdd Keychain(s) Select the previously created Keychain to add it to the Scan Scope. Note: you can have multiple Keychains associated with a Scan Job, so if there is a need or desire to separate credentials in to multiple Keychains, this can be accomodated for.\nClick the Update button in the upper right hand corner to save the changes\nAdd Scheduling (optional) After an initial scan is completed, it\u0026rsquo;s common for clients to set up a periodic scan of their enviroment to capture changes in communications and performance over a given time period.\nFor now, we\u0026rsquo;ll leave this set to the defaul of \u0026ldquo;Don\u0026rsquo;t schedule scan job\u0026rdquo;, but you\u0026rsquo;ll see that clicking on the \u0026ldquo;Schedule scan job\u0026rdquo; option allows you to set the scan frequency.\nThis is generally set to run daily, but can be run more frequently as appropriate. Note: If scheduling is enabled, the frequency must be greater than the Maximum duration set in the Scan Details section.\nNote: If the ServerMetrics script is enabled, the metrics will be captured every 5 minutes and reported to the system upon each subsequent scan, so there isn\u0026rsquo;t a need to scan multiple times a day to account for variations in utilization.\nStart Scan Job Now that your Scan Job is configured, it\u0026rsquo;s time to get the scan running\n"
},
{
	"uri": "/4_modulefour.html",
	"title": "Hugo Framework and Markdown",
	"tags": [],
	"description": "",
	"content": "Hugo Framework and Markdown Setting Up The Workshop: AWS Hosted Or Self-paced By utilizing the Hugo language localization settings, directing the workshop towards a specific setup can be simplified. The Language setting in the config.toml file will allow you to distinguish between having one option or both. Commenting out one of the languages will hide all files that are related to that setup. By default, only the self-guided setup will be enabled. To enable switching, set disableLanguageSwitchingButton to false in the config.toml. If you want to have only the Event Engine setup, set the defaultContentLanguage at the top of the config.toml file to ee.\nThe Entry Point Of The Workshop And Naming Conventions All modifications should be done to files in the content folder. _index.md serves as the main entry point to your workshop. Adding modules can be done utilizing the format of #_title as a folder within content. By adding a number value to the title, this helps to keep the files structured in parity with the content of the workshop. A good practice for file naming is to have the folder be the module number and the submodule numbers add to that number reflecting their order. For example, the first module is 1_ModuleOne and the submodules would be 11_SubmoduleOne, 12_SubmoduleTwo, and so forth. To ensure the modules and submodules follow the correct structure order, adjust the \u0026ldquo;weight\u0026rdquo; value in the heading of the file to reflect the order you wish to use. Three module examples are included in this template with the second being split based upon the method of setup. The same rules apply for submodules. _index.md will be the entry point of that module. Submodules should be named with the format of {module number}{weight}_{title}.{language}.md. For example, 11_Foreword.md would be the first submodule of module one in the default language/setup. 31_PartnerSetup.ee.md would be the first submodule of module 3 in the EventEngine language/setup.\nWorking With Hugo Markdown and Shortcode The following links will supply you with all the reference documentation about Hugo markdown. For more experienced developers, inline HTML is also an option to add more customization. For example \u0026lt;p style='text-align: left;'\u0026gt; inline will allow you to adjust your text placement.\nMarkdown and Shortcode Resources The following links are your go-to resource for markdown and shortcode reference in building your workshop: Markdown cheat sheet https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet Learn theme markdown https://learn.netlify.app/en/cont/markdown/ Menu extras and shortcuts https://learn.netlify.app/en/cont/menushortcuts/ Using Font Awesome Emoji\u0026rsquo;s https://learn.netlify.app/en/cont/icons/ to help your page pop Adding Images and Static Media Any images and static media to be included in the workshop need to be placed in the static/images folder. The format to display an image is as follows: ![Alternate Text](/images/imagename.jpg) For example, the markdown for this dog is ![An adorable puppy](/images/dog.jpg) and the image is in the static/images folder. Creating Links The format for creating links is [Link Display Text](http://example.com). For example, this link Hugo Framework was created using [Hugo Framework](https://gohugo.io/about/what-is-hugo/).\nThe \u0026ldquo;More\u0026rdquo; Menu Section This section of the menu on the left is designed to add additional resources that are related to the workshop but not necessarily part of the workshop itself. To modify these links, edit the sections marked [[menu.shortcuts]] in the config.toml located in the root folder. The \u0026ldquo;name\u0026rdquo; portion will be what is displayed in the menu. The \u0026ldquo;url\u0026rdquo; should be the address of the link. The \u0026ldquo;weight\u0026rdquo; setting will adjust the display order, similar to the other \u0026ldquo;weight\u0026rdquo; settings utilized in indexes and modules mentioned previously.\nEnsuring Pages Appear In Both Setup Versions A shortcut to creating the workshop with different setup versions is utilizing the localization functionality of Hugo. By adding a secondary extension to the filename, this file will be included in the specific version of the workshop. Currently, the base utilizes the format *.ee.md to signify that the page is to be used in the AWS EventEngine setup. Much of the time, the files will be the same as the content only differs at specific points. It is necessary to add them, however, to make sure that the common content is duplicated across both versions. If you wish to change the secondary extension or default version, this can be done in the config.toml file in the heading and [Languages] sections.\n"
},
{
	"uri": "/1_moduleone/14_workshopprerequisites.html",
	"title": "Workshop Prerequisites",
	"tags": [],
	"description": "",
	"content": "Workshop Prerequisites Before we get started In order to engage in this hands-on workshop, you will need to have a user provisioned on two CloudSphere tenants. If you haven\u0026rsquo;t already received your access credentials, please use the below link to complete the user request form.\nAccess request link\nOnce you receive the access email, you will be provided with a number of credentials and important details for the workshop. In addition to the necessary access, it is expected that you have completed the L200 training related to CloudSphere. If you haven\u0026rsquo;t completed this yet, please use the link below to complete this training prior, in order to ensure the best understanding of the solution and subsequent use cases.\nL200 Training link\nNext Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\n"
},
{
	"uri": "/2_moduletwo_setup/25_startscanjob.html",
	"title": "Start Scan Job",
	"tags": [],
	"description": "",
	"content": " Starting your Scan Job Now that you have configured your Scan Job, it\u0026rsquo;s time to scan the environment.\nExecuting a Scan Job Select the Scan Job created in the previous step\nClick the large blue Start button in the upper left side of the screen\nYou can also cancel the Scan Job from this screen at any time.\nReviewing a Scan Job Status Once the Scan Job kicks off, you\u0026rsquo;ll see a real-time progress bar indicating the status of the Scan Job\nOnce the Scan Job is completed, you\u0026rsquo;ll see the progress, completeness and additional details regarding the total number of devices and IPs scanned.\nIn the case of a partial failure, you\u0026rsquo;ll be able to review each target IP address with a status of PartialScan or CredentialFailed in order to remediate as necessary. The Scan info column will provide high level detail related to what info was captured or the nature of the failure.\nScan Results Review Now that you\u0026rsquo;ve completed your scan, it\u0026rsquo;s time to review the results, let\u0026rsquo;s see what we\u0026rsquo;ve got!\n"
},
{
	"uri": "/1_moduleone/15_nextsteps.html",
	"title": "Workshop Next Steps",
	"tags": [],
	"description": "",
	"content": "Workshop Next Steps Submodule Five Heading This paragraph block should be an brief explanation of the next steps to take after the prerequisites have been set up. Diagrams or code samples can be shown to give a visual explanation of what will be taking place during the building of the solution. An example of content guidance can be found at the bottom of this page.\nNext Section Heading This paragraph block can optionally be utilized to lead into the next section of the workshop.\nExample of content guidance Configuring Your Solution While working through the workshop modules, you will progressively build a 3-tier web application by utilizing core AWS services. We will provide you with any code examples and any directions specific to the set up approach we will be utilizing. Some of these may be skipped if you already have the required accounts and tools.\n"
},
{
	"uri": "/2_moduletwo_setup/26_scanresults.html",
	"title": "Scan Results Review",
	"tags": [],
	"description": "",
	"content": " Scan Results Review Once the discovery is done, all the data (servers and services scanned) will be populated in the IT Explorer view in the UI.\nFrom the computer systems, processes, and communication details captured, the following sub-sections of data are created:\nServices Servers Found Groups Applications Found Applications Services Services identify groups of related applications that provide one or more functions.\nFor instance, a Microsoft Exchange system is made of a number of Exchange Servers and Stores that together, form a single system providing an email Service. The set of WebServers, Application Servers, and Database Servers provide a merchant WebSite from an eCommerce Service.\nServers The CloudSphere Platform allows capturing Physical and Virtual Servers, Cloud Instances, Operating System level, and Virtualization level Clusters, as well as Containers (like Docker).\nServers overview tab - contains the details of the server, including the OS details and hardware details. Communication tab - provides the communication of the server with other servers and applications. Found Groups Found Groups are auto-generated by Cloudsphere to provide hints on potential services. They capture communicating found applications and a few application components to show the relationship. They are built and maintained in real-time as Communication and/or FoundCommunication relationships are created and removed. These generated found groups can be converted to service by means of fingerprinting and templating. A group could also be a service that has not been fully identified (i.e. a potential service). Applications \u0026amp; Found Applications Applications - capture software such as Web Servers, Application Servers, Mail Servers, Database Servers, Middleware (MoM, Message Servers, Directory Servers), etc. Application Clusters - capture a group of homogenous Applications that together provide a service to client applications. Ex Database Clusters, Messaging system clusters, Hadoop Clusters, etc. Found Applications - are the processes that are communicating with each other, are potential applications, and can be converted into applications by means of fingerprinting. Great Job!! You\u0026rsquo;ve completed the first module of the Migration Planning workshop. From here, we\u0026rsquo;ll move on to the second module, Deep Data Exploration. We hope you found this training helpful and look forward to engaging in the second portion of this workshop!\n"
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]